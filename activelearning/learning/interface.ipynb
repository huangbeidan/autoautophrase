{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "sys.path.insert(0, '/Users/beidan/RASHIP/nrde/autoautophrase/activelearning/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from featureExtraction.hierclusteringscipy import cleandata, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datahandler:\n",
    "    def __init__(self):\n",
    "        self.dataset = pd.read_csv('../../outputs/features_results_all_withphrase.csv')\n",
    "        self.dataset = self.cleandata(self.dataset, 17)\n",
    "        self.X_normalized = normalize(self.dataset.iloc[:, list(range(1,18))])\n",
    "        self.phrases = self.dataset.iloc[:, 0].values.tolist()\n",
    "        self.status = [0] * len(self.X_normalized)\n",
    "\n",
    "    def cleandata(self, dataset, columnidx):\n",
    "        f_knownphrase = dataset.iloc[:, [columnidx]].values\n",
    "        for i in range(len(f_knownphrase)):\n",
    "            if math.isnan(f_knownphrase[i]):\n",
    "                f_knownphrase[i] = 0\n",
    "        dataset.iloc[:, [columnidx]] = f_knownphrase\n",
    "        return dataset\n",
    "\n",
    "    def deleteItem(self, phrase):\n",
    "        idx = self.phrases.index(phrase)\n",
    "        self.status[idx] = -1\n",
    "    \n",
    "    def getdata(self):\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                             phrase  freq  f_len  max_subgram_freq  \\\n0                               NaN    14      1                 0   \n1                         JJ amaps)     1      2                 0   \n2                      JJ component    30      2                 0   \n3  NN naval warfare experimentation     1      4                67   \n4                       NN nl sound     1      3                 1   \n\n   partial_order  min_support  mutual_confidence  f_avg_wordlength  f_pos_nn  \\\n0              0         1.00               -1.0              0.00     0.000   \n1              0         0.07               -1.0              4.00     0.500   \n2              0         2.14               -1.0              5.50     0.500   \n3              0         0.07               -1.0              7.25     0.750   \n4              0         0.07               -1.0              3.00     0.667   \n\n   f_pos_prop  f_pos_verb  f_pos_adj  f_pos_deter  f_pos_empty  f_pos_other  \\\n0         0.0         0.0        0.0          0.0        1.000          0.0   \n1         0.0         0.0        0.0          0.0        0.500          0.0   \n2         0.0         0.0        0.0          0.0        0.500          0.0   \n3         0.0         0.0        0.0          0.0        0.250          0.0   \n4         0.0         0.0        0.0          0.0        0.333          0.0   \n\n   f_completeness  f_postagUniqueness  is_know_phrase  \n0               0                   0             0.0  \n1               0                   0             1.0  \n2               0                   0             1.0  \n3               0                   0             2.0  \n4               0                   0             1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phrase</th>\n      <th>freq</th>\n      <th>f_len</th>\n      <th>max_subgram_freq</th>\n      <th>partial_order</th>\n      <th>min_support</th>\n      <th>mutual_confidence</th>\n      <th>f_avg_wordlength</th>\n      <th>f_pos_nn</th>\n      <th>f_pos_prop</th>\n      <th>f_pos_verb</th>\n      <th>f_pos_adj</th>\n      <th>f_pos_deter</th>\n      <th>f_pos_empty</th>\n      <th>f_pos_other</th>\n      <th>f_completeness</th>\n      <th>f_postagUniqueness</th>\n      <th>is_know_phrase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>14</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>-1.0</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JJ amaps)</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.07</td>\n      <td>-1.0</td>\n      <td>4.00</td>\n      <td>0.500</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.500</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JJ component</td>\n      <td>30</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.14</td>\n      <td>-1.0</td>\n      <td>5.50</td>\n      <td>0.500</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.500</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NN naval warfare experimentation</td>\n      <td>1</td>\n      <td>4</td>\n      <td>67</td>\n      <td>0</td>\n      <td>0.07</td>\n      <td>-1.0</td>\n      <td>7.25</td>\n      <td>0.750</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.250</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NN nl sound</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.07</td>\n      <td>-1.0</td>\n      <td>3.00</td>\n      <td>0.667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "# convert NA to 0 in column 17\n",
    "dh = datahandler()\n",
    "dh.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what I want - df.groupby('A')['C'].apply(lambda x: \"{%s}\" % ', '.join(x))\n",
    "# very useful url - https://stackoverflow.com/questions/17841149/pandas-groupby-how-to-get-a-union-of-strings/17841294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index by - phrases.index('NN naval warfare experimentation')\n",
    "g1 = dataset.groupby(pd.cut(dataset.f_len, bins=20))['phrase'].apply(list)\n",
    "g1list = g1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.2-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}